{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((125, 256, 320, 1), (74, 256, 320, 1))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "META_SRC = \"selected/0_0_0_metadata_extended.csv\"\n",
    "TRAIN_DATA_DIR = \"selected\"\n",
    "TRAIN_X_LABEL = \"uic_value\"\n",
    "\n",
    "VALID_META_SRC = \"validation/selected/0_0_0_metadata_extended.csv\"\n",
    "VALID_DATA_DIR = \"validation/selected\"\n",
    "\n",
    "train_meta_df = pd.read_csv(META_SRC)\n",
    "train_meta_df = shuffle(train_meta_df)\n",
    "\n",
    "valid_meta_df = pd.read_csv(VALID_META_SRC)\n",
    "valid_meta_df = shuffle(valid_meta_df)\n",
    "\n",
    "\n",
    "class ImgReader:\n",
    "    def read(self, file: str, format_=\"jpg\") -> np.ndarray:\n",
    "        return plt.imread(file, format_)\n",
    "\n",
    "    def read_multiple(self, files, format_=\"jpg\") -> np.ndarray:\n",
    "        return np.asarray([self.read(f, format_) for f in files])\n",
    "\n",
    "\n",
    "img_reader = ImgReader()\n",
    "\n",
    "\n",
    "def list_files_from_df(root_dir: str, df: pd.DataFrame):\n",
    "    files = [os.path.join(root_dir, f) for f in df[\"filename\"].values]\n",
    "\n",
    "    return files\n",
    "\n",
    "\n",
    "def get_all_images_with_column(data_dir, metadata_df, col_name: str, is_shuffle=False):\n",
    "    metadata_df.dropna(inplace=True)\n",
    "    metadata_df = metadata_df[metadata_df['uic_value'].str.len() == 15]\n",
    "    df = metadata_df[[\"filename\", col_name]]\n",
    "    if is_shuffle:\n",
    "        df = shuffle(df)\n",
    "    files = list_files_from_df(data_dir, df)\n",
    "    images = img_reader.read_multiple(files)\n",
    "    col_values = df[col_name].values\n",
    "\n",
    "    return images, col_values\n",
    "\n",
    "def normalize_imgs(imgs):\n",
    "    new_imgs_shape = (imgs.shape[0], imgs.shape[1], imgs.shape[2], 1)\n",
    "    imgs = imgs.reshape(new_imgs_shape)\n",
    "    imgs = imgs/255.0\n",
    "    return imgs\n",
    "\n",
    "is_shuffle = True\n",
    "imgs, uids = get_all_images_with_column(TRAIN_DATA_DIR, train_meta_df, TRAIN_X_LABEL, is_shuffle)\n",
    "imgs = normalize_imgs(imgs)\n",
    "\n",
    "valid_imgs, valid_types = get_all_images_with_column(VALID_DATA_DIR, valid_meta_df, TRAIN_X_LABEL, is_shuffle)\n",
    "valid_imgs = normalize_imgs(valid_imgs)\n",
    "\n",
    "\n",
    "input_shape = (256, 320, 1)\n",
    "valid_imgs.shape, imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:112: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: \tLoss: 4.752693\n",
      "Train Epoch: \tLoss: 4.382185\n",
      "Train Epoch: \tLoss: 4.018901\n",
      "Train Epoch: \tLoss: 3.743085\n",
      "Train Epoch: \tLoss: 3.614478\n",
      "loss6.615778923034668\n",
      "Train Epoch: \tLoss: 3.489098\n",
      "Train Epoch: \tLoss: 3.268129\n",
      "Train Epoch: \tLoss: 3.056163\n",
      "Train Epoch: \tLoss: 2.935723\n",
      "Train Epoch: \tLoss: 2.830981\n",
      "loss4.586660861968994\n",
      "Train Epoch: \tLoss: 2.710960\n",
      "Train Epoch: \tLoss: 2.539115\n",
      "Train Epoch: \tLoss: 2.393106\n",
      "Train Epoch: \tLoss: 2.242167\n",
      "Train Epoch: \tLoss: 2.100329\n",
      "loss3.8824961185455322\n",
      "Train Epoch: \tLoss: 1.935457\n",
      "Train Epoch: \tLoss: 1.997348\n",
      "Train Epoch: \tLoss: 1.743876\n",
      "Train Epoch: \tLoss: 1.567148\n",
      "Train Epoch: \tLoss: 1.634711\n",
      "loss2.468554973602295\n",
      "Train Epoch: \tLoss: 1.470736\n",
      "Train Epoch: \tLoss: 1.434754\n",
      "Train Epoch: \tLoss: 1.189843\n",
      "Train Epoch: \tLoss: 1.304060\n",
      "Train Epoch: \tLoss: 1.164233\n",
      "loss1.7225819826126099\n",
      "Train Epoch: \tLoss: 1.054721\n",
      "Train Epoch: \tLoss: 0.957703\n",
      "Train Epoch: \tLoss: 0.850618\n",
      "Train Epoch: \tLoss: 0.814303\n",
      "Train Epoch: \tLoss: 0.782418\n",
      "loss1.569588303565979\n",
      "Train Epoch: \tLoss: 0.813578\n",
      "Train Epoch: \tLoss: 0.767398\n",
      "Train Epoch: \tLoss: 0.738516\n",
      "Train Epoch: \tLoss: 0.624903\n",
      "Train Epoch: \tLoss: 0.667808\n",
      "loss1.2961159944534302\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "META_SRC = \"selected/0_0_0_metadata_extended.csv\"\n",
    "TRAIN_DATA_DIR = \"selected\"\n",
    "TRAIN_X_LABEL = \"uic_value\"\n",
    "\n",
    "VALID_META_SRC = \"validation/selected/0_0_0_metadata_extended.csv\"\n",
    "VALID_DATA_DIR = \"validation/selected\"\n",
    "\n",
    "train_meta_df = pd.read_csv(META_SRC)\n",
    "train_meta_df = shuffle(train_meta_df)\n",
    "\n",
    "valid_meta_df = pd.read_csv(VALID_META_SRC)\n",
    "valid_meta_df = shuffle(valid_meta_df)\n",
    "\n",
    "\n",
    "class ImgReader:\n",
    "    def read(self, file: str, format_=\"jpg\") -> np.ndarray:\n",
    "        return plt.imread(file, format_)\n",
    "\n",
    "    def read_multiple(self, files, format_=\"jpg\") -> np.ndarray:\n",
    "        return np.asarray([self.read(f, format_) for f in files])\n",
    "\n",
    "\n",
    "img_reader = ImgReader()\n",
    "\n",
    "\n",
    "def list_files_from_df(root_dir: str, df: pd.DataFrame):\n",
    "    files = [os.path.join(root_dir, f) for f in df[\"filename\"].values]\n",
    "\n",
    "    return files\n",
    "\n",
    "\n",
    "def get_all_images_with_column(data_dir, metadata_df, col_name: str, is_shuffle=False):\n",
    "    metadata_df.dropna(inplace=True)\n",
    "    metadata_df = metadata_df[metadata_df['uic_value'].str.len() == 15]\n",
    "    df = metadata_df[[\"filename\", col_name]]\n",
    "    if is_shuffle:\n",
    "        df = shuffle(df)\n",
    "    files = list_files_from_df(data_dir, df)\n",
    "    images = img_reader.read_multiple(files)\n",
    "    col_values = df[col_name].values\n",
    "\n",
    "    return images, col_values\n",
    "\n",
    "def normalize_imgs(imgs):\n",
    "    new_imgs_shape = (imgs.shape[0], imgs.shape[1], imgs.shape[2], 1)\n",
    "    imgs = imgs.reshape(new_imgs_shape)\n",
    "    imgs = imgs/255.0\n",
    "    return imgs\n",
    "\n",
    "is_shuffle = True\n",
    "imgs, uids = get_all_images_with_column(TRAIN_DATA_DIR, train_meta_df, TRAIN_X_LABEL, is_shuffle)\n",
    "imgs = normalize_imgs(imgs)\n",
    "\n",
    "valid_imgs, valid_types = get_all_images_with_column(VALID_DATA_DIR, valid_meta_df, TRAIN_X_LABEL, is_shuffle)\n",
    "valid_imgs = normalize_imgs(valid_imgs)\n",
    "\n",
    "\n",
    "input_shape = (256, 320, 1)\n",
    "valid_imgs.shape, imgs.shape\n",
    "\n",
    "x_img = valid_imgs.reshape(-1, 256 * 320)\n",
    "x_test = imgs.reshape(-1, 256 * 320)\n",
    "tables = []\n",
    "y_test_tables = []\n",
    "for i in valid_types:\n",
    "    tables.append([int(i) for i in i.replace('-', '').strip()[:2]])\n",
    "y = np.asarray(tables)\n",
    "for i in uids:\n",
    "    y_test_tables.append([int(i) for i in i.replace('-', '').strip()[:2]])\n",
    "y_test = np.asarray(y_test_tables)\n",
    "\n",
    "\n",
    "class MLPNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLPNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(256 * 320, 256)\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=256)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=128)\n",
    "\n",
    "        self.dropout2 = nn.Dropout(0.4)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "        self.fc4 = nn.Linear(128, 10)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(self.bn1(F.relu(self.fc1(x))))\n",
    "        x = self.dropout2(self.bn2(F.relu(self.fc2(x))))\n",
    "        x2 = self.fc4(x)\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x), F.log_softmax(x2)\n",
    "\n",
    "    def name(self):\n",
    "        return \"MLP\"\n",
    "\n",
    "\n",
    "model = MLPNet().to(device)\n",
    "\n",
    "optimizer = optim.Adamax(model.parameters(), lr=0.007)\n",
    "\n",
    "\n",
    "def train(epoch=5):\n",
    "    for i in range(epoch):\n",
    "        model.train()\n",
    "        data, target = torch.from_numpy(x_img).type(torch.cuda.FloatTensor), torch.from_numpy(np.asarray(y)).type(torch.cuda.FloatTensor)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        #         print(data.dtype, target.dtype)\n",
    "        output1, output2 = model(data)\n",
    "        loss1 = F.nll_loss(output1, torch.tensor(y[:, 0]).type(torch.cuda.LongTensor))\n",
    "        loss2 = F.nll_loss(output2, torch.tensor(y[:, 1]).type(torch.cuda.LongTensor))\n",
    "        loss = loss1 + loss2\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print('Train Epoch: \\tLoss: {:.6f}'.format(loss.item()))\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "def test(epoch=1):\n",
    "    for i in range(epoch):\n",
    "        model.eval()\n",
    "        data, target = torch.from_numpy(x_test).float(), torch.from_numpy(np.asarray(y_test)).float()\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        #         print(data.dtype, target.dtype)\n",
    "        output1, output2 = model(data)\n",
    "        loss1 = F.nll_loss(output1, torch.tensor(y_test[:, 0]).type(torch.cuda.LongTensor))\n",
    "        loss2 = F.nll_loss(output2, torch.tensor(y_test[:, 1]).type(torch.cuda.LongTensor))\n",
    "        loss = loss1 + loss2\n",
    "        print(f'loss{loss}')\n",
    "\n",
    "\n",
    "# train()\n",
    "y[:, 0], y[:, 1]\n",
    "train()\n",
    "test()\n",
    "train()\n",
    "test()\n",
    "train()\n",
    "test()\n",
    "train()\n",
    "test()\n",
    "train()\n",
    "test()\n",
    "train()\n",
    "test()\n",
    "train()\n",
    "test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
