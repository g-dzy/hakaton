{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((125, 256, 320, 1), (74, 256, 320, 1))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "META_SRC = \"selected/0_0_0_metadata_extended.csv\"\n",
    "TRAIN_DATA_DIR = \"selected\"\n",
    "TRAIN_X_LABEL = \"uic_value\"\n",
    "\n",
    "VALID_META_SRC = \"validation/selected/0_0_0_metadata_extended.csv\"\n",
    "VALID_DATA_DIR = \"validation/selected\"\n",
    "\n",
    "train_meta_df = pd.read_csv(META_SRC)\n",
    "train_meta_df = shuffle(train_meta_df)\n",
    "\n",
    "valid_meta_df = pd.read_csv(VALID_META_SRC)\n",
    "valid_meta_df = shuffle(valid_meta_df)\n",
    "\n",
    "\n",
    "class ImgReader:\n",
    "    def read(self, file: str, format_=\"jpg\") -> np.ndarray:\n",
    "        return plt.imread(file, format_)\n",
    "\n",
    "    def read_multiple(self, files, format_=\"jpg\") -> np.ndarray:\n",
    "        return np.asarray([self.read(f, format_) for f in files])\n",
    "\n",
    "\n",
    "img_reader = ImgReader()\n",
    "\n",
    "\n",
    "def list_files_from_df(root_dir: str, df: pd.DataFrame):\n",
    "    files = [os.path.join(root_dir, f) for f in df[\"filename\"].values]\n",
    "\n",
    "    return files\n",
    "\n",
    "\n",
    "def get_all_images_with_column(data_dir, metadata_df, col_name: str, is_shuffle=False):\n",
    "    metadata_df.dropna(inplace=True)\n",
    "    metadata_df = metadata_df[metadata_df['uic_value'].str.len() == 15]\n",
    "    df = metadata_df[[\"filename\", col_name]]\n",
    "    if is_shuffle:\n",
    "        df = shuffle(df)\n",
    "    files = list_files_from_df(data_dir, df)\n",
    "    images = img_reader.read_multiple(files)\n",
    "    col_values = df[col_name].values\n",
    "\n",
    "    return images, col_values\n",
    "\n",
    "def normalize_imgs(imgs):\n",
    "    new_imgs_shape = (imgs.shape[0], imgs.shape[1], imgs.shape[2], 1)\n",
    "    imgs = imgs.reshape(new_imgs_shape)\n",
    "    imgs = imgs/255.0\n",
    "    return imgs\n",
    "\n",
    "is_shuffle = True\n",
    "imgs, uids = get_all_images_with_column(TRAIN_DATA_DIR, train_meta_df, TRAIN_X_LABEL, is_shuffle)\n",
    "imgs = normalize_imgs(imgs)\n",
    "\n",
    "valid_imgs, valid_types = get_all_images_with_column(VALID_DATA_DIR, valid_meta_df, TRAIN_X_LABEL, is_shuffle)\n",
    "valid_imgs = normalize_imgs(valid_imgs)\n",
    "\n",
    "\n",
    "input_shape = (256, 320, 1)\n",
    "valid_imgs.shape, imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:133: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: \tLoss: 9.512673\n",
      "Train Epoch: \tLoss: 9.359974\n",
      "Train Epoch: \tLoss: 9.306278\n",
      "Train Epoch: \tLoss: 9.145170\n",
      "Train Epoch: \tLoss: 8.855949\n",
      "Train Epoch: \tLoss: 8.655087\n",
      "Train Epoch: \tLoss: 8.363224\n",
      "Train Epoch: \tLoss: 8.161484\n",
      "Train Epoch: \tLoss: 8.025332\n",
      "Train Epoch: \tLoss: 7.768181\n",
      "Train Epoch: \tLoss: 7.487407\n",
      "Train Epoch: \tLoss: 7.306524\n",
      "Train Epoch: \tLoss: 7.245602\n",
      "Train Epoch: \tLoss: 6.914216\n",
      "Train Epoch: \tLoss: 6.771936\n",
      "VAL 10.465245246887207\n",
      "Train Epoch: \tLoss: 6.448531\n",
      "Train Epoch: \tLoss: 6.286090\n",
      "Train Epoch: \tLoss: 6.246289\n",
      "Train Epoch: \tLoss: 6.030532\n",
      "Train Epoch: \tLoss: 5.855522\n",
      "Train Epoch: \tLoss: 5.637320\n",
      "Train Epoch: \tLoss: 5.549393\n",
      "Train Epoch: \tLoss: 5.392629\n",
      "Train Epoch: \tLoss: 5.152772\n",
      "Train Epoch: \tLoss: 4.925815\n",
      "Train Epoch: \tLoss: 4.785442\n",
      "Train Epoch: \tLoss: 4.623872\n",
      "Train Epoch: \tLoss: 4.484368\n",
      "Train Epoch: \tLoss: 4.429594\n",
      "Train Epoch: \tLoss: 4.402902\n",
      "(81920,)\n",
      "(1, 81920)\n",
      "xd\n",
      "VAL 5.69647216796875\n",
      "Train Epoch: \tLoss: 4.039452\n",
      "Train Epoch: \tLoss: 3.925108\n",
      "Train Epoch: \tLoss: 3.995346\n",
      "Train Epoch: \tLoss: 3.902375\n",
      "Train Epoch: \tLoss: 3.780629\n",
      "Train Epoch: \tLoss: 3.699240\n",
      "Train Epoch: \tLoss: 3.608635\n",
      "Train Epoch: \tLoss: 3.411677\n",
      "Train Epoch: \tLoss: 3.500747\n",
      "Train Epoch: \tLoss: 3.435165\n",
      "Train Epoch: \tLoss: 3.315536\n",
      "Train Epoch: \tLoss: 3.238022\n",
      "Train Epoch: \tLoss: 3.222335\n",
      "Train Epoch: \tLoss: 3.215008\n",
      "Train Epoch: \tLoss: 3.198262\n",
      "VAL 5.732186317443848\n",
      "Train Epoch: \tLoss: 3.140238\n",
      "Train Epoch: \tLoss: 3.164140\n",
      "Train Epoch: \tLoss: 3.234801\n",
      "Train Epoch: \tLoss: 3.071608\n",
      "Train Epoch: \tLoss: 3.113206\n",
      "Train Epoch: \tLoss: 3.148213\n",
      "Train Epoch: \tLoss: 3.050440\n",
      "Train Epoch: \tLoss: 2.946695\n",
      "Train Epoch: \tLoss: 2.936145\n",
      "Train Epoch: \tLoss: 2.886669\n",
      "Train Epoch: \tLoss: 2.962806\n",
      "Train Epoch: \tLoss: 3.027851\n",
      "Train Epoch: \tLoss: 2.897786\n",
      "Train Epoch: \tLoss: 2.918994\n",
      "Train Epoch: \tLoss: 2.770441\n",
      "VAL 5.790095329284668\n",
      "Train Epoch: \tLoss: 2.755782\n",
      "Train Epoch: \tLoss: 2.666364\n",
      "Train Epoch: \tLoss: 2.788234\n",
      "Train Epoch: \tLoss: 2.685387\n",
      "Train Epoch: \tLoss: 2.599843\n",
      "Train Epoch: \tLoss: 2.796426\n",
      "Train Epoch: \tLoss: 2.755324\n",
      "Train Epoch: \tLoss: 2.646780\n",
      "Train Epoch: \tLoss: 2.635215\n",
      "Train Epoch: \tLoss: 2.661429\n",
      "Train Epoch: \tLoss: 2.627622\n",
      "Train Epoch: \tLoss: 2.690644\n",
      "Train Epoch: \tLoss: 2.649205\n",
      "Train Epoch: \tLoss: 2.602416\n",
      "Train Epoch: \tLoss: 2.576483\n",
      "VAL 6.377708911895752\n",
      "Train Epoch: \tLoss: 2.569634\n",
      "Train Epoch: \tLoss: 2.532299\n",
      "Train Epoch: \tLoss: 2.618765\n",
      "Train Epoch: \tLoss: 2.413019\n",
      "Train Epoch: \tLoss: 2.471896\n",
      "Train Epoch: \tLoss: 2.396609\n",
      "Train Epoch: \tLoss: 2.300175\n",
      "Train Epoch: \tLoss: 2.420449\n",
      "Train Epoch: \tLoss: 2.424146\n",
      "Train Epoch: \tLoss: 2.434398\n",
      "Train Epoch: \tLoss: 2.272319\n",
      "Train Epoch: \tLoss: 2.311682\n",
      "Train Epoch: \tLoss: 2.217003\n",
      "Train Epoch: \tLoss: 2.367101\n",
      "Train Epoch: \tLoss: 2.405383\n",
      "VAL 8.023906707763672\n",
      "Train Epoch: \tLoss: 2.423595\n",
      "Train Epoch: \tLoss: 2.336062\n",
      "Train Epoch: \tLoss: 2.315625\n",
      "Train Epoch: \tLoss: 2.277854\n",
      "Train Epoch: \tLoss: 2.264938\n",
      "Train Epoch: \tLoss: 2.249595\n",
      "Train Epoch: \tLoss: 2.319267\n",
      "Train Epoch: \tLoss: 2.169163\n",
      "Train Epoch: \tLoss: 2.124353\n",
      "Train Epoch: \tLoss: 2.172854\n",
      "Train Epoch: \tLoss: 2.229049\n",
      "Train Epoch: \tLoss: 2.017493\n",
      "Train Epoch: \tLoss: 2.025266\n",
      "Train Epoch: \tLoss: 2.145017\n",
      "Train Epoch: \tLoss: 2.153252\n",
      "VAL 10.477652549743652\n",
      "Train Epoch: \tLoss: 2.013387\n",
      "Train Epoch: \tLoss: 1.958314\n",
      "Train Epoch: \tLoss: 1.949308\n",
      "Train Epoch: \tLoss: 2.029785\n",
      "Train Epoch: \tLoss: 2.085383\n",
      "Train Epoch: \tLoss: 1.934145\n",
      "Train Epoch: \tLoss: 2.058397\n",
      "Train Epoch: \tLoss: 2.065668\n",
      "Train Epoch: \tLoss: 1.948154\n",
      "Train Epoch: \tLoss: 1.782771\n",
      "Train Epoch: \tLoss: 1.995338\n",
      "Train Epoch: \tLoss: 1.816060\n",
      "Train Epoch: \tLoss: 1.941823\n",
      "Train Epoch: \tLoss: 1.978533\n",
      "Train Epoch: \tLoss: 1.821135\n",
      "VAL 13.292213439941406\n",
      "Train Epoch: \tLoss: 1.932185\n",
      "Train Epoch: \tLoss: 1.882224\n",
      "Train Epoch: \tLoss: 1.864847\n",
      "Train Epoch: \tLoss: 1.784245\n",
      "Train Epoch: \tLoss: 1.817471\n",
      "Train Epoch: \tLoss: 1.656668\n",
      "Train Epoch: \tLoss: 1.680181\n",
      "Train Epoch: \tLoss: 1.774677\n",
      "Train Epoch: \tLoss: 1.725235\n",
      "Train Epoch: \tLoss: 1.853465\n",
      "Train Epoch: \tLoss: 1.607223\n",
      "Train Epoch: \tLoss: 1.772654\n",
      "Train Epoch: \tLoss: 1.612961\n",
      "Train Epoch: \tLoss: 1.642154\n",
      "Train Epoch: \tLoss: 1.506521\n",
      "VAL 14.41904067993164\n",
      "Train Epoch: \tLoss: 1.622982\n",
      "Train Epoch: \tLoss: 1.674312\n",
      "Train Epoch: \tLoss: 1.619615\n",
      "Train Epoch: \tLoss: 1.501035\n",
      "Train Epoch: \tLoss: 1.647226\n",
      "Train Epoch: \tLoss: 1.619995\n",
      "Train Epoch: \tLoss: 1.571776\n",
      "Train Epoch: \tLoss: 1.516968\n",
      "Train Epoch: \tLoss: 1.457975\n",
      "Train Epoch: \tLoss: 1.490081\n",
      "Train Epoch: \tLoss: 1.444675\n",
      "Train Epoch: \tLoss: 1.578890\n",
      "Train Epoch: \tLoss: 1.459303\n",
      "Train Epoch: \tLoss: 1.418157\n",
      "Train Epoch: \tLoss: 1.529158\n",
      "VAL 16.131656646728516\n",
      "Train Epoch: \tLoss: 1.417620\n",
      "Train Epoch: \tLoss: 1.466708\n",
      "Train Epoch: \tLoss: 1.555363\n",
      "Train Epoch: \tLoss: 1.488708\n",
      "Train Epoch: \tLoss: 1.357913\n",
      "Train Epoch: \tLoss: 1.292294\n",
      "Train Epoch: \tLoss: 1.437495\n",
      "Train Epoch: \tLoss: 1.247379\n",
      "Train Epoch: \tLoss: 1.372859\n",
      "Train Epoch: \tLoss: 1.406644\n",
      "Train Epoch: \tLoss: 1.320168\n",
      "Train Epoch: \tLoss: 1.281414\n",
      "Train Epoch: \tLoss: 1.277255\n",
      "Train Epoch: \tLoss: 1.191110\n",
      "Train Epoch: \tLoss: 1.280833\n",
      "VAL 16.659618377685547\n",
      "Train Epoch: \tLoss: 1.282084\n",
      "Train Epoch: \tLoss: 1.159585\n",
      "Train Epoch: \tLoss: 1.302117\n",
      "Train Epoch: \tLoss: 1.062778\n",
      "Train Epoch: \tLoss: 1.291997\n",
      "Train Epoch: \tLoss: 1.179298\n",
      "Train Epoch: \tLoss: 1.382112\n",
      "Train Epoch: \tLoss: 1.284307\n",
      "Train Epoch: \tLoss: 1.056246\n",
      "Train Epoch: \tLoss: 1.027399\n",
      "Train Epoch: \tLoss: 1.165746\n",
      "Train Epoch: \tLoss: 1.123397\n",
      "Train Epoch: \tLoss: 1.296769\n",
      "Train Epoch: \tLoss: 1.205438\n",
      "Train Epoch: \tLoss: 1.006582\n",
      "VAL 19.32473373413086\n",
      "Train Epoch: \tLoss: 1.250936\n",
      "Train Epoch: \tLoss: 1.225364\n",
      "Train Epoch: \tLoss: 1.220985\n",
      "Train Epoch: \tLoss: 1.229039\n",
      "Train Epoch: \tLoss: 1.117402\n",
      "Train Epoch: \tLoss: 1.289964\n",
      "Train Epoch: \tLoss: 1.049854\n",
      "Train Epoch: \tLoss: 1.185760\n",
      "Train Epoch: \tLoss: 1.160203\n",
      "Train Epoch: \tLoss: 1.376471\n",
      "Train Epoch: \tLoss: 1.049449\n",
      "Train Epoch: \tLoss: 0.890592\n",
      "Train Epoch: \tLoss: 1.087679\n",
      "Train Epoch: \tLoss: 0.970801\n",
      "Train Epoch: \tLoss: 0.992204\n",
      "VAL 20.87529945373535\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "META_SRC = \"selected/0_0_0_metadata_extended.csv\"\n",
    "TRAIN_DATA_DIR = \"selected\"\n",
    "TRAIN_X_LABEL = \"uic_value\"\n",
    "\n",
    "VALID_META_SRC = \"validation/selected/0_0_0_metadata_extended.csv\"\n",
    "VALID_DATA_DIR = \"validation/selected\"\n",
    "\n",
    "train_meta_df = pd.read_csv(META_SRC)\n",
    "train_meta_df = shuffle(train_meta_df)\n",
    "\n",
    "valid_meta_df = pd.read_csv(VALID_META_SRC)\n",
    "valid_meta_df = shuffle(valid_meta_df)\n",
    "\n",
    "\n",
    "class ImgReader:\n",
    "    def read(self, file: str, format_=\"jpg\") -> np.ndarray:\n",
    "        return plt.imread(file, format_)\n",
    "\n",
    "    def read_multiple(self, files, format_=\"jpg\") -> np.ndarray:\n",
    "        return np.asarray([self.read(f, format_) for f in files])\n",
    "\n",
    "\n",
    "img_reader = ImgReader()\n",
    "\n",
    "\n",
    "def list_files_from_df(root_dir: str, df: pd.DataFrame):\n",
    "    files = [os.path.join(root_dir, f) for f in df[\"filename\"].values]\n",
    "\n",
    "    return files\n",
    "\n",
    "\n",
    "def get_all_images_with_column(data_dir, metadata_df, col_name: str, is_shuffle=False):\n",
    "    metadata_df.dropna(inplace=True)\n",
    "    metadata_df = metadata_df[metadata_df['uic_value'].str.len() == 15]\n",
    "    df = metadata_df[[\"filename\", col_name]]\n",
    "    if is_shuffle:\n",
    "        df = shuffle(df)\n",
    "    files = list_files_from_df(data_dir, df)\n",
    "    images = img_reader.read_multiple(files)\n",
    "    col_values = df[col_name].values\n",
    "\n",
    "    return images, col_values\n",
    "\n",
    "def normalize_imgs(imgs):\n",
    "    new_imgs_shape = (imgs.shape[0], imgs.shape[1], imgs.shape[2], 1)\n",
    "    imgs = imgs.reshape(new_imgs_shape)\n",
    "    imgs = imgs/255.0\n",
    "    return imgs\n",
    "\n",
    "is_shuffle = True\n",
    "imgs, uids = get_all_images_with_column(TRAIN_DATA_DIR, train_meta_df, TRAIN_X_LABEL, is_shuffle)\n",
    "imgs = normalize_imgs(imgs)\n",
    "\n",
    "valid_imgs, valid_types = get_all_images_with_column(VALID_DATA_DIR, valid_meta_df, TRAIN_X_LABEL, is_shuffle)\n",
    "valid_imgs = normalize_imgs(valid_imgs)\n",
    "\n",
    "\n",
    "input_shape = (256, 320, 1)\n",
    "valid_imgs.shape, imgs.shape\n",
    "\n",
    "x_img = valid_imgs.reshape(-1, 256 * 320)\n",
    "x_test = imgs.reshape(-1, 256 * 320)\n",
    "tables = []\n",
    "y_test_tables = []\n",
    "for i in valid_types:\n",
    "    tables.append([int(i) for i in i.replace('-', '').strip()[4:8]])\n",
    "y = np.asarray(tables)\n",
    "for i in uids:\n",
    "    y_test_tables.append([int(i) for i in i.replace('-', '').strip()[4:8]])\n",
    "y_test = np.asarray(y_test_tables)\n",
    "\n",
    "\n",
    "class MLPNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLPNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(256 * 320, 3000)\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=3000)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        self.fc2 = nn.Linear(3000, 256)\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=256)\n",
    "\n",
    "        self.fc33 = nn.Linear(256, 128)\n",
    "        self.bn33 = nn.BatchNorm1d(num_features=128)\n",
    "\n",
    "        self.fc333 = nn.Linear(128, 64)\n",
    "        self.bn333 = nn.BatchNorm1d(num_features=64)\n",
    "\n",
    "        self.fc3333 = nn.Linear(64, 128)\n",
    "        self.bn3333 = nn.BatchNorm1d(num_features=128)\n",
    "\n",
    "        self.dropout2 = nn.Dropout(0.4)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "        self.fc4 = nn.Linear(128, 10)\n",
    "        self.fc5= nn.Linear(128, 10)\n",
    "\n",
    "        self.fc6 = nn.Linear(128, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(self.bn1(F.relu(self.fc1(x))))\n",
    "        x = self.dropout2(self.bn2(F.relu(self.fc2(x))))\n",
    "        x = self.dropout2(self.bn33(F.relu(self.fc33(x))))\n",
    "        x = self.dropout2(self.bn333(F.relu(self.fc333(x))))\n",
    "        x = self.dropout2(self.bn3333(F.relu(self.fc3333(x))))\n",
    "\n",
    "\n",
    "        x2 = self.fc4(x)\n",
    "        x3 = self.fc5(x)\n",
    "\n",
    "        x4 = self.fc6(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x), F.log_softmax(x2), F.log_softmax(x3), F.log_softmax(x4)\n",
    "\n",
    "\n",
    "\n",
    "model = MLPNet().to(device)\n",
    "\n",
    "optimizer = optim.Adamax(model.parameters(), lr=6e-3)\n",
    "\n",
    "\n",
    "def train(epoch=15):\n",
    "    for i in range(epoch):\n",
    "        model.train()\n",
    "        data, target = torch.from_numpy(x_img).type(torch.cuda.FloatTensor), torch.from_numpy(np.asarray(y)).type(torch.cuda.FloatTensor)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        #         print(data.dtype, target.dtype)\n",
    "        output1, output2, output3, output4 = model(data)\n",
    "        loss1 = F.nll_loss(output1, torch.tensor(y[:, 0]).type(torch.cuda.LongTensor))\n",
    "        loss2 = F.nll_loss(output2, torch.tensor(y[:, 1]).type(torch.cuda.LongTensor))\n",
    "        loss3 = F.nll_loss(output3, torch.tensor(y[:, 2]).type(torch.cuda.LongTensor))\n",
    "\n",
    "        loss4 = F.nll_loss(output4, torch.tensor(y[:, 3]).type(torch.cuda.LongTensor))\n",
    "\n",
    "        loss = loss1 + loss2 + loss3 + loss4\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print('Train Epoch: \\tLoss: {:.6f}'.format(loss.item()))\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "def test(epoch=1):\n",
    "    for i in range(epoch):\n",
    "        model.eval()\n",
    "        data, target = torch.from_numpy(x_test).float(), torch.from_numpy(np.asarray(y_test)).float()\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        #         print(data.dtype, target.dtype)\n",
    "        output1, output2, output3, output4 = model(data)\n",
    "        loss1 = F.nll_loss(output1, torch.tensor(y_test[:, 0]).type(torch.cuda.LongTensor))\n",
    "        loss2 = F.nll_loss(output2, torch.tensor(y_test[:, 1]).type(torch.cuda.LongTensor))\n",
    "        loss3 = F.nll_loss(output3, torch.tensor(y_test[:, 2]).type(torch.cuda.LongTensor))\n",
    "\n",
    "        loss4 = F.nll_loss(output4, torch.tensor(y_test[:, 3]).type(torch.cuda.LongTensor))\n",
    "        loss = loss1 + loss2 + loss3 + loss4\n",
    "        print(f'VAL {loss}')\n",
    "        \n",
    "\n",
    "\n",
    "def get_prob(data):\n",
    "    model.eval()\n",
    "    print(data.shape)\n",
    "    if len(data.shape) <= 1:\n",
    "        data = data.reshape(1, -1)\n",
    "        print(data.shape)\n",
    "\n",
    "    data = torch.from_numpy(data).float()\n",
    "    data = data.to(device)\n",
    "    output1, output2, output3, output4 = model(data)\n",
    "    print('xd')\n",
    "    return output1, output2, output3, output4\n",
    "\n",
    "\n",
    "\n",
    "train()\n",
    "test()\n",
    "train()\n",
    "get_prob(x_test[0])\n",
    "test()\n",
    "train()\n",
    "test()\n",
    "train()\n",
    "test()\n",
    "train()\n",
    "test()\n",
    "train()\n",
    "test()\n",
    "train()\n",
    "test()\n",
    "train()\n",
    "test()\n",
    "train()\n",
    "test()\n",
    "train()\n",
    "test()\n",
    "train()\n",
    "test()\n",
    "train()\n",
    "test()\n",
    "train()\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
